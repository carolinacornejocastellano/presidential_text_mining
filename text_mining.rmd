---
title: "_Palabras que se las lleva el viento_"
subtitle: "Exploring presidential inauguration speeches of the last decade"
output: html_document
---

## Introduction

This is a project to explore the priorities of Peruvian governments in the last decade. The data used is the presidential inauguration speeches of the last decade. The speeches are available in the website of the Peruvian Congress. The speeches are in Spanish, so I used Google Translate to translate them to English. The speeches are available in the folder "data".

## Data

```{r load libraries}
libraries <- c("tidyverse", 
               "tidytext", 
               "wordcloud", 
               "RColorBrewer", 
               "reshape2", 
               "igraph", 
               "ggraph", 
               "widyr", 
               "tm", 
               "quanteda", 
               "quanteda.textplots", 
               "topicmodels")

for (lib in libraries) {
  suppressPackageStartupMessages(library(lib,
    character.only = TRUE
  ))
}
rm(lib, libraries)
```

```{r download speeches}
presidents <-
  c("Dina Boluarte", 
    "Pedro Castillo", 
    "Francisco Sagasti", 
    "Martin Vizcarra", 
    "Pedro Pablo Kuczynski", 
    "Ollanta Humala", 
    "Alejandro Toledo", 
    "Valentin Paniagua", 
    "Alberto Fujimori second term", 
    "Alberto Fujimori first term")

links <- paste0(
  "https://raw.githubusercontent.com/cornellano/presidential_text_mining/main/",
  tolower(gsub(" ", "_", presidents)), ".md")
```

```{r}
df <- tibble(
  president = presidents,
  date = c("2022-12-07", 
          "2021-07-28", 
          "2020-11-17", 
          "2018-03-23", 
          "2016-07-28",
          "2011-07-28", 
          "2001-07-28", 
          "2000-11-11", 
          "1995-07-28",
          "1990-07-28"), 
  url = links
)
```

```{r}
# Read speeches
df$speech <- df$url %>% 
    map_chr(~ read_lines(.x, 
      locale = locale(encoding = "UTF-8")) %>% 
        paste(collapse = "\n"))

# delete URLs from df
df$url <- NULL
```

## Data preparation
Now we will tokenize the speeches and remove stopwords:

```{r store stopwords in Spanish as a vector}
stopwords_es <- stopwords::stopwords("es",
  source = "stopwords-iso"
)
```

```{r delete stopwords from the original df}
df_no_stopwords <- df %>%
  unnest_tokens(word, speech) %>%
  anti_join(data.frame(word = stopwords_es),
            by = "word") %>%
  group_by(president, date) %>%
  summarize(clean_speech = paste(word,
                                 collapse = " "))
```
```{r}
df_tokenized <- df %>% 
  unnest_tokens(word, speech) %>% 
  filter(!word %in% stopwords_es)
```

```{r general word ranking}
df_tokenized %>%
  count(word,
    sort = TRUE
  )
```

```{r plot the most common words in presidential speeches}
df_tokenized %>% 
  count(president, 
    word, 
    sort = TRUE
  ) %>% 
  filter(n > 7) %>% # words that each president used more than 7 times
  ggplot(aes(x = reorder(word, n), 
            y = n, 
            fill = president)) +
  geom_col() +
    facet_wrap(~president, 
    scales = "free") +
    coord_flip() +
    scale_fill_manual(values = brewer.pal(8, "BrBG")) +
    theme_minimal() +
    ggtitle("Most Common Words in Presidential Inauguration Speeches", 
            subtitle = "From 1990 to 2022") +
    labs(
      x = "Word",
      y = "Frequency", 
      fill = "President"
    ) +
    theme(
      plot.title = element_text(
        hjust = 0.5,
        size = 20,
        face = "bold"
      ),
      plot.subtitle = element_text(
        hjust = 0.5,
        size = 14
      )
    )
```

## N-grams


We will analyze the most common bigrams:

```{r most common bigrams in all speeches}
df_no_stopwords %>%
  unnest_tokens(bigram,
                clean_speech,
                token = "ngrams",
                n = 2) %>%
  filter(!is.na(bigram)) %>%
  count(bigram, sort = TRUE) %>% 
  head(20)
```

```{r}
bigrams <-  df_no_stopwords %>%
  unnest_tokens(bigram, 
                clean_speech, 
                token = "ngrams", 
                n = 2)

# Bigrams by president
bigram_counts <- bigrams %>%
  count(president, 
        bigram, 
        sort = TRUE)

# Top bigrams for each president
top_bigrams <- bigram_counts %>%
  group_by(president) %>%
  top_n(2, n) %>%
  arrange(president)

top_bigrams
```
The following plot does not show well in the inline preview. Please, click in "Show in New window" button for it to be displayed well:

```{r bigrams plot}
ggplot(top_bigrams, 
       aes(x = reorder(bigram, n), 
           y = n, 
           fill = president)) +
  geom_col() +
  facet_wrap(~ president, 
             scales = "free") +
  coord_flip() +
  scale_fill_manual(values = brewer.pal(10, "BrBG")) +
  theme_minimal() +
  ggtitle("Most Common Bigrams in Presidential Speeches", 
          subtitle = "From 1990 to 2022") +
  labs(x = "Bigram", 
       y = "Frequency", 
       fill = "President") +
  theme(plot.title = element_text(hjust = 0.5, 
                                  size = 20, 
                                  face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, 
                                     size = 14))

```


Now, let's take a look to the most common trigrams:

```{r}
df_no_stopwords %>%
  unnest_tokens(trigram,
                clean_speech,
                token = "ngrams",
                n = 3) %>%
  filter(!is.na(trigram)) %>%
  count(trigram, sort = TRUE) %>% 
  head(20)
```
```{r}
trigrams <-  df_no_stopwords %>%
  unnest_tokens(trigram, 
                clean_speech, 
                token = "ngrams", 
                n = 3)

# trigrams by president
trigram_counts <- trigrams %>%
  count(president, 
        trigram, 
        sort = TRUE)

# Top bigrams for each president
top_trigrams <- trigram_counts %>%
  group_by(president) %>%
  top_n(1, n) %>%
  arrange(president)

top_trigrams
```
```{r}
ggplot(top_trigrams, 
       aes(x = reorder(trigram, n), 
           y = n, 
           fill = president)) +
  geom_col() +
  facet_wrap(~ president, 
             scales = "free") +
  coord_flip() +
  scale_fill_manual(values = brewer.pal(10, "BrBG")) +
  theme_minimal() +
  ggtitle("Most Common Trigrams in Presidential Speeches", 
          subtitle = "From 1990 to 2022") +
  labs(x = "Trigram", 
       y = "Frequency", 
       fill = "President") +
  theme(plot.title = element_text(hjust = 0.5, 
                                  size = 20, 
                                  face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, 
                                     size = 14))
```
Tres de los cuatro NO fueron elegidos democráticamente, sino que asumieron el cargo de emergencia, no tienen trigrams identificados. Por esa razón, aparecen muchos, imposible de leer.

## Sentiment analysis

We will perform sentiment analysis using the AFINN lexicon:

```{r}
# Perform sentiment analysis
sentiment <- tokenized_speeches %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(president) %>% 
  summarise(sentiment = sum(value))

# Plot sentiment
sentiment %>% 
  ggplot(aes(x = reorder(president, sentiment), 
             y = sentiment, 
             fill = president)) + 
  geom_col() + 
  theme_minimal() + 
  coord_flip() + 
  labs(x = "President", 
       y = "Sentiment", 
       title = "Sentiment Analysis of Presidential Inauguration Speeches", 
       subtitle = "Last Decade", 
       fill = "President")
```


## Latent Dirichlet Allocation
