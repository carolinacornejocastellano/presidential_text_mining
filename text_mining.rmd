---
title: "_Palabras que se las lleva el viento_"
subtitle: "Exploring presidential inauguration speeches of the last decade"
output: html_document
date: \today
bibliography: ["C:/Users/Carolina/Documents/0cast/biblatex.bib"]
link-citations: true
lang: en-US
linkReferences: true
nameInLink: true
---

## Introduction

As of this writing, the current Peruvian government counts over 66 deaths in just 3 months of government [@rebazaTheySayWe2023]. Dina Boluarte is Peru’s first female president and the sixth person to occupy the presidential chair in four years [@olmoPresidentesAnosPor2022]. She ascended to office on December 7, 2022, after the previous president, elected by popular vote, dissolved the congress after only 16 months in charge and many attempts of being removed from office by Congress.

The analysis of the political motives of the perpetual Peruvian political crisis exceeds the purpose of this exercise. However, it will suffice to mention that, before Boluarte, perhaps the one who aroused the most popular rage was Manuel Merino, who governed alone from November 10 to 15, 2020 —less than a week!— and ended up resigning because of massive protests throughout the country [@redaccionbbcnewsmundoOlaProtestasPeru2020]. The last government that lasted 5 years, the constitutional term of office, was that of Ollanta Humala (2011 - 2016). Since then, mandates have lasted months or even just days. 

This exercise aims to characterize the topics and sentiments addressed in the first Message to the Nation (or inaugural speech) of each of the last 10 presidents. The hypothesis is that their inaugural speeches, analyzed through text mining techniques, will help to characterize the context in which they ascended to power, and that there will be clear differences in the topics, length and sentiments of those who ascended by popular vote, and those who took office by emergency succession.

## Data

The speeches were manually downloaded in .pdf format from official sources: the archive of the [Congress of the Republic of Peru](https://www.congreso.gob.pe/participacion/museo/congreso/mensajes-presidenciales/) and the [Single Digital Platform of the Peruvian State](https://www.gob.pe/mensajepresidencial]). Only the inaugural speech of Alan Garcia (2006-2011) was not found, as the one of Alejandro Toledo (2001-2006) was wrongly uploaded in its place. Therefore, to complete 10 presidents, the speech of the first period of government of the dictator Alberto Fujimori (1900 - 1995) was also extracted.

These pdf were then converted to markdown, superficially checked for special characters, and uploaded to GitHub so that we could retrieve them directly from there and make this exercise reproducible without the need to attach them. The GitHub repository is accessible [here](https://github.com/carolinacornejocastellano/presidential_text_mining). 


Thus, we will work with 10 presidential messages, proclaimed on the following dates:

- Dina Boluarte (December 7, 2022).
- Pedro Castillo (December 28, 2021)
- Francisco Sagasti (November 17, 2020)
- Martin Vizcarra (March 23, 2018).
- Pedro Pablo Kuczynski (July 28, 2016).
- Ollanta Humala (July 28, 2011)
- Alejandro Toledo (July 28, 2001)
- Valentín Paniagua (November 11, 2000)
- Alberto Fujimori (second term) (July 28, 1995)
- Alberto Fujimori (first term) (July 28, 1990)

Of these, Dina Boluarte, Francisco Sagasti, Martín Vizcarra and Valentín Paniagua were not elected by popular vote, but were assigned for different reasons and in different contexts, with different popular approval. There is also a debate about Alberto Fujimori's second term, whether he was legitimately elected or manipulated the results in obedience to his dictatorial spirit. On the other hand, Manuel Merino was not purposely considered: because of the way he took office and his brief period, many do not consider him a president, only a coup plotter or usurper. 

## Pre-processing 

```{r load libraries}
libraries <- c(
  "tidyverse",
  "tidytext",
  "textdata",
  "wordcloud",
  "RColorBrewer",
  "reshape2",
  "igraph",
  "ggraph",
  "widyr",
  "tm",
  "quanteda",
  "quanteda.textplots",
  "topicmodels",
  "syuzhet",
  "parallel",
  "textstem",
  "SentimentAnalysis"
)

for (lib in libraries) {
  suppressPackageStartupMessages(library(lib,
    character.only = TRUE
  ))
}
rm(lib, libraries)
```

```{r download speeches}
presidents <-
  c("Dina Boluarte", 
    "Pedro Castillo", 
    "Francisco Sagasti", 
    "Martin Vizcarra", 
    "Pedro Pablo Kuczynski", 
    "Ollanta Humala", 
    "Alejandro Toledo", 
    "Valentin Paniagua", 
    "Alberto Fujimori second term", 
    "Alberto Fujimori first term")

links <- paste0(
  "https://raw.githubusercontent.com/carolinacornejocastellano/presidential_text_mining/main/",
  tolower(gsub(" ", "_", presidents)), ".md")
```

```{r}
df <- tibble(
  president = presidents,
  date = c("2022-12-07", 
          "2021-07-28", 
          "2020-11-17", 
          "2018-03-23", 
          "2016-07-28",
          "2011-07-28", 
          "2001-07-28", 
          "2000-11-11", 
          "1995-07-28",
          "1990-07-28"), 
  url = links
)
```

```{r}
# Read speeches
df$speech <- df$url %>% 
    map_chr(~ read_lines(.x, 
      locale = locale(encoding = "UTF-8")) %>% 
        paste(collapse = "\n"))

# delete URLs' column from df
df$url <- NULL
```

## Data preparation
Now we will tokenize the speeches and remove stopwords:

```{r store stopwords in Spanish as a vector}
stopwords_es <- stopwords::stopwords("es",
  source = "stopwords-iso"
)
```

```{r delete stopwords from the original df}
df_no_stopwords <- df %>%
  unnest_tokens(word, speech) %>%
  anti_join(data.frame(word = stopwords_es),
            by = "word") %>%
  group_by(president, date) %>%
  summarize(clean_speech = paste(word,
                                 collapse = " "))
```

```{r}
df_tokenized <- df_no_stopwords %>% 
  unnest_tokens(word, clean_speech) %>% 
  filter(!word %in% stopwords_es)
```

```{r general word ranking}
df_tokenized %>%
  count(word,
    sort = TRUE
  )
```

```{r plot the most common words in presidential speeches}
df_tokenized %>% 
  count(president, 
    word, 
    sort = TRUE
  ) %>% 
  filter(n > 7) %>% # words that each president used more than 7 times
  ggplot(aes(x = reorder(word, n), 
            y = n, 
            fill = president)) +
  geom_col() +
    facet_wrap(~president, 
    scales = "free") +
    coord_flip() +
    scale_fill_manual(values = brewer.pal(8, "BrBG")) +
    theme_minimal() +
    ggtitle("Most Common Words in Presidential Inauguration Speeches", 
            subtitle = "From 1990 to 2022") +
    labs(
      x = "Word",
      y = "Frequency", 
      fill = "President"
    ) +
    theme(
      plot.title = element_text(
        hjust = 0.5,
        size = 20,
        face = "bold"
      ),
      plot.subtitle = element_text(
        hjust = 0.5,
        size = 14
      )
    )
```

## N-grams


We will analyze the most common bigrams:

```{r most common bigrams in all speeches}
df_no_stopwords %>%
  unnest_tokens(bigram,
                clean_speech,
                token = "ngrams",
                n = 2) %>%
  filter(!is.na(bigram)) %>%
  count(bigram, sort = TRUE) %>% 
  head(20)
```

```{r}
bigrams <-  df_no_stopwords %>%
  unnest_tokens(bigram, 
                clean_speech, 
                token = "ngrams", 
                n = 2)

# Bigrams by president
bigram_counts <- bigrams %>%
  count(president, 
        bigram, 
        sort = TRUE)

# Top bigrams for each president
top_bigrams <- bigram_counts %>%
  group_by(president) %>%
  top_n(2, n) %>%
  arrange(president)

top_bigrams
```
The following plot does not show well in the inline preview. Please, click in "Show in New window" button for it to be displayed well:

```{r bigrams plot}
ggplot(top_bigrams, 
       aes(x = reorder(bigram, n), 
           y = n, 
           fill = president)) +
  geom_col() +
  facet_wrap(~ president, 
             scales = "free") +
  coord_flip() +
  scale_fill_manual(values = brewer.pal(10, "BrBG")) +
  theme_minimal() +
  ggtitle("Most Common Bigrams in Presidential Speeches", 
          subtitle = "From 1990 to 2022") +
  labs(x = "Bigram", 
       y = "Frequency", 
       fill = "President") +
  theme(plot.title = element_text(hjust = 0.5, 
                                  size = 20, 
                                  face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, 
                                     size = 14))

```


Now, let's take a look to the most common trigrams:

```{r}
df_no_stopwords %>%
  unnest_tokens(trigram,
                clean_speech,
                token = "ngrams",
                n = 3) %>%
  filter(!is.na(trigram)) %>%
  count(trigram, sort = TRUE) %>% 
  head(20)
```

```{r}
trigrams <-  df_no_stopwords %>%
  unnest_tokens(trigram, 
                clean_speech, 
                token = "ngrams", 
                n = 3)

# trigrams by president
trigram_counts <- trigrams %>%
  count(president, 
        trigram, 
        sort = TRUE)

# Top bigrams for each president
top_trigrams <- trigram_counts %>%
  group_by(president) %>%
  top_n(2, n) %>%
  arrange(president)

top_trigrams
```

```{r}
ggplot(top_trigrams, 
       aes(x = reorder(trigram, n), 
           y = n, 
           fill = president)) +
  geom_col() +
  facet_wrap(~ president, 
             scales = "free") +
  coord_flip() +
  scale_fill_manual(values = brewer.pal(10, "BrBG")) +
  theme_minimal() +
  ggtitle("Most Common Trigrams in Presidential Speeches", 
          subtitle = "From 1990 to 2022") +
  labs(x = "Trigram", 
       y = "Frequency", 
       fill = "President") +
  theme(plot.title = element_text(hjust = 0.5, 
                                  size = 20, 
                                  face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, 
                                     size = 14))
```
Tres de los cuatro NO fueron elegidos democráticamente, sino que asumieron el cargo de emergencia, no tienen trigrams identificados. Por esa razón, aparecen muchos, imposible de leer.

## Sentiment analysis

```{r }
sentiments_spanish <- analyzeSentiment(df_tokenized$word,
  language = "spanish"
)
head(sentiments_spanish)
```

```{r}
df_sentiments <- data.frame(df_tokenized$word,
  sentiment = convertToDirection(sentiments_spanish$SentimentGI))
df_sentiments
```

```{r}
table(df_sentiments$sentiment)
```

```{r}
df_sentiments %>%
  group_by(sentiment) %>%
  summarise(number = n()) %>% 
  ggplot(aes(x = sentiment,
            y=number)) +
  geom_bar(aes(fill=sentiment),
              stat = "identity") +
  scale_fill_manual(values = brewer.pal(4, "BrBG")) +
  theme_minimal() +
  ggtitle("Most Common Sentiments in Presidential Speeches", 
          subtitle = "From 1990 to 2022") +
  labs(x = "Sentiment", 
       y = "Frequency", 
       fill = "President") +
  theme(plot.title = element_text(hjust = 0.5, 
                                  size = 20, 
                                  face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, 
                                     size = 14))
```

Now, with the `syuzhet` package. Este paquete asocia textos a 8 emociones y 2 sentimientos. Tanto más excede el valor a 0, más pronunciada es la emoción o sentimiento.

```{r parallelization}
cl <- makeCluster(4)
clusterExport(cl = cl, c("get_sentiment", 
                         "get_sent_values", "get_nrc_sentiment", "get_nrc_values", "parLapply"))
```

```{r}
sentiment_nrc <- get_nrc_sentiment(df_tokenized$word, 
                                   cl=cl,
                                   language = "spanish")
stopCluster(cl)
```

```{r}
head(sentiment_nrc)
```

Results are not as expected. Could they be improved if we lemmatize the words, instead of presenting them in their original form?

```{r stemming}
df_tokenized_stemm <- dfm(df_tokenized$word,
                          remove_punct = TRUE, 
                          stem = TRUE)
```

```{r stemming}
df_tokenized_lemma <- df_tokenized %>%
  mutate(word_lemmatized = lemmatize_words(word, 
                                           language = "es"))

head(df_tokenized_lemma)
```
```{r}
df_tokenized_stemm <- stemDocument(df_tokenized$word, 
                                    language = "spanish")

```

```{r}
realnews_dfm <- dfm(df_tokenized$word, remove_punct = TRUE, stem = TRUE)

```

```{r}
realnews_dfm
```

```{r}
set.seed(100)

textplot_wordcloud(realnews_dfm, min_count = 6, random_order = FALSE,
                   rotation = .25, 
                   color = RColorBrewer::brewer.pal(8,"Dark2"))
```

----
Most common sentiments per president


```{r}
df_sentiments %>%
  group_by(Year, President, sentiment) %>%
  summarise(number = n()) %>% 
  ggplot(aes(x = sentiment,
            y=number)) +
  geom_bar(aes(fill=President),
              stat = "identity") +
  scale_fill_manual(values = brewer.pal(length(unique(df_sentiments$President)), "Set3")) +
  theme_minimal() +
  ggtitle("Most Common Sentiments in Presidential Speeches", 
          subtitle = "From 1990 to 2022") +
  labs(x = "Sentiment", 
       y = "Frequency", 
       fill = "President") +
  theme(plot.title = element_text(hjust = 0.5, 
                                  size = 20, 
                                  face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, 
                                     size = 14))
```

## Latent Dirichlet Allocation

```{#r}
# Create a Document-Term Matrix (DTM)
dtm <- df_tokenized %>%
  count(president, word) %>%
  cast_dtm(president, word, n)

# LDA model with 5 topics
lda_model <- LDA(dtm, k = 5)

# Get the probabilities of words per topic
term_topic_prob <- tidy(lda_model, matrix = "beta")

# Top 10 words per topic
top_terms <- term_topic_prob %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Assign topics to documents
document_topic_prob <- tidy(lda_model, matrix = "gamma")

# Merge topics with original data
document_topic_merged <- df_no_stopwords %>%
  left_join(document_topic_prob,
    by = c("president" = "document")
  )

# Find the most probable topic for each president
president_topics <- document_topic_merged %>%
  group_by(president) %>%
  top_n(1, gamma) %>%
  select(president, topic)

```
